# åŸºäºPaddleSegçš„é¥æ„Ÿåœ°å—åˆ†å‰²

## ä¸€ã€é¡¹ç›®èƒŒæ™¯ä»‹ç»
é¥æ„Ÿå½±åƒåœ°å—åˆ†å‰², æ—¨åœ¨å¯¹é¥æ„Ÿå½±åƒè¿›è¡Œåƒç´ çº§å†…å®¹è§£æï¼Œå¯¹é¥æ„Ÿå½±åƒä¸­æ„Ÿå…´è¶£çš„ç±»åˆ«è¿›è¡Œæå–å’Œåˆ†ç±»ï¼Œåœ¨åŸä¹¡è§„åˆ’ã€é˜²æ±›æ•‘ç¾ç­‰é¢†åŸŸå…·æœ‰å¾ˆé«˜çš„å®ç”¨ä»·å€¼ï¼Œåœ¨å·¥ä¸šç•Œä¹Ÿå—åˆ°äº†å¹¿æ³›å…³æ³¨ã€‚ç°æœ‰çš„é¥æ„Ÿå½±åƒåœ°å—åˆ†å‰²æ•°æ®å¤„ç†æ–¹æ³•å±€é™äºç‰¹å®šçš„åœºæ™¯å’Œç‰¹å®šçš„æ•°æ®æ¥æºï¼Œä¸”ç²¾åº¦æ— æ³•æ»¡è¶³éœ€æ±‚ã€‚å› æ­¤åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä»ç„¶å¤§é‡ä¾èµ–äºäººå·¥å¤„ç†ï¼Œéœ€è¦æ¶ˆè€—å¤§é‡çš„äººåŠ›ã€ç‰©åŠ›ã€è´¢åŠ›ã€‚æœ¬é¡¹ç›®æ—¨åœ¨è¡¡é‡é¥æ„Ÿå½±åƒåœ°å—åˆ†å‰²æ¨¡å‹åœ¨å¤šä¸ªç±»åˆ«ï¼ˆå¦‚å»ºç­‘ã€é“è·¯ã€æ—åœ°ç­‰ï¼‰ä¸Šçš„æ•ˆæœï¼Œåˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œå¯¹å¤šæ¥æºã€å¤šåœºæ™¯çš„å¼‚æ„é¥æ„Ÿå½±åƒæ•°æ®è¿›è¡Œå……åˆ†æŒ–æ˜ï¼Œæ‰“é€ é«˜æ•ˆã€å®ç”¨çš„ç®—æ³•ï¼Œæé«˜é¥æ„Ÿå½±åƒçš„åˆ†ææå–èƒ½åŠ›ã€‚

## äºŒã€æ•°æ®ä»‹ç»
### [é¥æ„Ÿå½±åƒåˆ†å‰²â€”â€”WHDLD](https://aistudio.baidu.com/aistudio/datasetdetail/55589/0)
### æ•°æ®é›†èƒŒæ™¯
WHDLDæ•°æ®é›†  
- åŒ…å«6ç§ç±»å‹çš„é¥æ„Ÿåœ°ç‰©ç±»å‹  
- æå–è‡ªUC Merced  
- ç”±æ­¦æ±‰å¤§å­¦äº2018å¹´å‘å¸ƒ  

### æ•°æ®é›†å†…å®¹
å½±åƒä¿¡æ¯ï¼š  
- image size: 256 * 256 * 3  
- image number: 4940  

![](https://ai-studio-static-online.cdn.bcebos.com/3d1cd30362ba41b8afa6729a5be44a00338c47c6615f49c680c68c226a7957f4)
![](https://ai-studio-static-online.cdn.bcebos.com/8a995f72b4a14cd5a2d20912d69cf99117d6aad9cd6445c9a8a1f901d826c2b8)

### æ ‡æ³¨ä¿¡æ¯
6ç±»

![](https://ai-studio-static-online.cdn.bcebos.com/67966da8ea174102a2f645f08b9be80497505773f1274d5494ce46aff8093b5a)

### æ¥æº
[https://sites.google.com/view/zhouwx/dataset#h.p_hQS2jYeaFpV0](https://sites.google.com/view/zhouwx/dataset#h.p_hQS2jYeaFpV0)

### å…¶ä»–è¯´æ˜
If you use WHDLD in any resulting publications, please cite the following works:
Shao, Z.; Yang, K.; Zhou, W. Performance Evaluation of Single-Label and Multi-Label Remote Sensing Image Retrieval Using a Dense Labeling Dataset. Remote Sens. 2018, 10(6), 964.
Shao, Z., Zhou, W., Deng, X., Zhang, M., & Cheng, Q. Multilabel Remote Sensing Image Retrieval Based on Fully Convolutional Network. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2020, 13, 318-328.

## ä¸‰ã€æ¨¡å‹ä»‹ç»
> References: [HardNeté£æ¡¨ï¼ˆPaddleï¼‰è®ºæ–‡å¤ç°(By:Jordan2020)](https://aistudio.baidu.com/aistudio/projectdetail/1848242)

**HarDNet**æŒ‡çš„æ˜¯Harmonic DenseNet: A low memory traffic networkï¼Œå…¶çªå‡ºçš„ç‰¹ç‚¹å°±æ˜¯ä½å†…å­˜å ç”¨ç‡ã€‚è¿‡å»å‡ å¹´ï¼Œéšç€æ›´å¼ºçš„è®¡ç®—èƒ½åŠ›å’Œæ›´å¤§çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒæ›´åŠ å¤æ‚çš„ç½‘ç»œã€‚å¯¹äºå®æ—¶åº”ç”¨ï¼Œæˆ‘ä»¬é¢ä¸´çš„é—®é¢˜æ˜¯å¦‚ä½•åœ¨æé«˜è®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œé™ä½åŠŸè€—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½œè€…ä»¬æå‡ºäº†HarDNetåœ¨ä¸¤è€…ä¹‹é—´å¯»æ±‚æœ€ä½³å¹³è¡¡ã€‚

HarDNetå¯ä»¥ç”¨äºå›¾åƒåˆ†å‰²ã€ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ï¼Œå…¶æ¶æ„æ˜¯åŸºäºDensely Connected Networkã€‚åœ¨HarDNetä¸­ï¼Œä½œè€…æå‡ºäº†Harmonic Dense Bocksçš„æ¦‚å¿µã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°è¯¥ç½‘ç»œå°±åƒå¤šä¸ªè°æ³¢ã€‚HarDNetçš„å…¨ç§°å°±æ˜¯Harmonic Densely Connected Networkã€‚  
![](https://ai-studio-static-online.cdn.bcebos.com/e3faeaed2ba74b1f867b673607332114935ec29f37d6468b99f5a7a6682df1a8)  
ä½œè€…å¯¹æ¯ä¸€å±‚çš„MoCæ–½åŠ ä¸€ä¸ªè½¯çº¦æŸï¼Œä»¥è®¾è®¡ä¸€ä¸ªä½CIOç½‘ç»œæ¨¡å‹ï¼Œå¹¶åˆç†å¢åŠ MACsã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œé¿å…ä½¿ç”¨MoCéå¸¸ä½çš„å±‚ï¼Œä¾‹å¦‚å…·æœ‰éå¸¸å¤§è¾“å…¥/è¾“å‡ºé€šé“æ¯”çš„Conv1x1å±‚ã€‚å—Densely Connected Networksçš„å¯å‘ï¼Œä½œè€…æå‡ºäº†Harmonic Densely Connected Network (HarD- Net) ã€‚é¦–å…ˆå‡å°‘æ¥è‡ªDenseNetçš„å¤§éƒ¨åˆ†å±‚è¿æ¥ï¼Œä»¥é™ä½çº§è”æŸè€—ã€‚ç„¶åï¼Œé€šè¿‡å¢åŠ å±‚çš„é€šé“å®½åº¦æ¥å¹³è¡¡è¾“å…¥/è¾“å‡ºé€šé“æ¯”ç‡ã€‚  
![](https://ai-studio-static-online.cdn.bcebos.com/ef3d058b1e0c42b583d479366eb2011252a8a0af79d041e7b63ca80c6d6d1c04)

## å››ã€ç¯å¢ƒå®‰è£…ä¸æ•°æ®å‡†å¤‡

### 1. PaddleSegçš„å®‰è£…ä¸ç¯å¢ƒé…ç½®


```python
# å®‰è£…paddlesegï¼Œå½“å‰ç‰ˆæœ¬ä¸º2.4.0
!pip install -q paddleseg==2.4.0
```

    [33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.
    You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.[0m


### 2. è§£å‹æ•°æ®é›†


```python
# è§£å‹è®­ç»ƒæ•°æ®é›†ä¸æ ‡è®°
!unzip -oq /home/aistudio/data/data55589/WHDLD.zip -d data/data55589

# æŸ¥çœ‹æ–‡ä»¶ç›®å½•
!tree data/data55589 -d
```

    data/data55589
    â””â”€â”€ WHDLD
        â”œâ”€â”€ Images
        â””â”€â”€ ImagesPNG
    
    3 directories


### 3. EISegæ ‡æ³¨æ•°æ®æ¼”ç¤º
> [EISegå®˜æ–¹æ–‡æ¡£](https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.2/contrib/EISeg)

EISeg(Efficient Interactive Segmentation)æ˜¯åŸºäºé£æ¡¨å¼€å‘çš„ä¸€ä¸ªé«˜æ•ˆæ™ºèƒ½çš„äº¤äº’å¼åˆ†å‰²æ ‡æ³¨è½¯ä»¶ã€‚æ¶µç›–äº†é«˜ç²¾åº¦å’Œè½»é‡çº§ç­‰ä¸åŒæ–¹å‘çš„é«˜è´¨é‡äº¤äº’å¼åˆ†å‰²æ¨¡å‹ï¼Œæ–¹ä¾¿å¼€å‘è€…å¿«é€Ÿå®ç°è¯­ä¹‰åŠå®ä¾‹æ ‡ç­¾çš„æ ‡æ³¨ï¼Œé™ä½æ ‡æ³¨æˆæœ¬ã€‚ å¦å¤–ï¼Œå°†EISegè·å–åˆ°çš„æ ‡æ³¨åº”ç”¨åˆ°PaddleSegæä¾›çš„å…¶ä»–åˆ†å‰²æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œä¾¿å¯å¾—åˆ°å®šåˆ¶åŒ–åœºæ™¯çš„é«˜ç²¾åº¦æ¨¡å‹ï¼Œæ‰“é€šåˆ†å‰²ä»»åŠ¡ä»æ•°æ®æ ‡æ³¨åˆ°æ¨¡å‹è®­ç»ƒåŠé¢„æµ‹çš„å…¨æµç¨‹ã€‚

#### **æ¨¡å‹å‡†å¤‡**
åœ¨ä½¿ç”¨EIsegå‰ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹å‚æ•°ã€‚EISegå¼€æ”¾äº†åœ¨COCO+LVISå’Œå¤§è§„æ¨¡äººåƒæ•°æ®ä¸Šè®­ç»ƒçš„å››ä¸ªæ ‡æ³¨æ¨¡å‹ï¼Œæ»¡è¶³é€šç”¨åœºæ™¯å’Œäººåƒåœºæ™¯çš„æ ‡æ³¨éœ€æ±‚ã€‚å…¶ä¸­æ¨¡å‹ç»“æ„å¯¹åº”EISegäº¤äº’å·¥å…·ä¸­çš„ç½‘ç»œé€‰æ‹©æ¨¡å—ï¼Œç”¨æˆ·éœ€è¦æ ¹æ®è‡ªå·±çš„åœºæ™¯éœ€æ±‚é€‰æ‹©ä¸åŒçš„ç½‘ç»œç»“æ„å’ŒåŠ è½½å‚æ•°ã€‚  
æœ¬é¡¹ç›®é€‰ç”¨çš„æ˜¯[hrnet18_ocr64_cocolvis](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18_ocr64_cocolvis.pdparams)æ¨¡å‹ã€‚
| æ¨¡å‹ç±»å‹ | é€‚ç”¨åœºæ™¯ | æ¨¡å‹ç»“æ„ | ä¸‹è½½åœ°å€|
| --- | --- | --- | ---|
| **é«˜ç²¾åº¦æ¨¡å‹**  | **é€‚ç”¨äºé€šç”¨åœºæ™¯çš„å›¾åƒæ ‡æ³¨ã€‚** | **HRNet18_OCR64** | **[hrnet18_ocr64_cocolvis](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18_ocr64_cocolvis.pdparams)** |
| è½»é‡åŒ–æ¨¡å‹  | é€‚ç”¨äºé€šç”¨åœºæ™¯çš„å›¾åƒæ ‡æ³¨ã€‚ |HRNet18s_OCR48 | [hrnet18s_ocr48_cocolvis](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18s_ocr48_cocolvis.pdparams) |
| é«˜ç²¾åº¦æ¨¡å‹  | é€‚ç”¨äºäººåƒæ ‡æ³¨åœºæ™¯ã€‚ |HRNet18_OCR64 | [hrnet18_ocr64_human](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18_ocr64_human.pdparams) |
| è½»é‡åŒ–æ¨¡å‹  | é€‚ç”¨äºäººåƒæ ‡æ³¨åœºæ™¯ã€‚ |HRNet18s_OCR48 | [hrnet18s_ocr48_human](https://bj.bcebos.com/paddleseg/dygraph/interactive_segmentation/ritm/hrnet18s_ocr48_human.pdparams) |

#### **å®‰è£…ä½¿ç”¨**

EISegæä¾›å¤šç§å®‰è£…æ–¹å¼ï¼Œå…¶ä¸­ä½¿ç”¨[pip](#PIP)å’Œ[è¿è¡Œä»£ç ](#è¿è¡Œä»£ç )æ–¹å¼å¯å…¼å®¹Windowsï¼ŒMac OSå’ŒLinuxã€‚ä¸ºäº†é¿å…ç¯å¢ƒå†²çªï¼Œæ¨èåœ¨condaåˆ›å»ºçš„è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ã€‚

ç‰ˆæœ¬è¦æ±‚:

* PaddlePaddle >= 2.1.0

PaddlePaddleå®‰è£…è¯·å‚è€ƒ[å®˜ç½‘](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html)ã€‚

è¿™é‡Œä½¿ç”¨pipå®‰è£…æ–¹å¼ï¼š

```shell
pip install eiseg
```
pipä¼šè‡ªåŠ¨å®‰è£…ä¾èµ–ã€‚å®‰è£…å®Œæˆåå‘½ä»¤è¡Œè¾“å…¥ï¼š
```shell
eiseg
```
å³å¯è¿è¡Œè½¯ä»¶ã€‚

#### **ä½¿ç”¨**

æ‰“å¼€è½¯ä»¶åï¼Œåœ¨å¯¹é¡¹ç›®è¿›è¡Œæ ‡æ³¨å‰ï¼Œéœ€è¦è¿›è¡Œå¦‚ä¸‹è®¾ç½®ï¼š

1. **æ¨¡å‹å‚æ•°åŠ è½½**

   é€‰æ‹©åˆé€‚çš„ç½‘ç»œï¼Œå¹¶åŠ è½½å¯¹åº”çš„æ¨¡å‹å‚æ•°ã€‚ç›®å‰åœ¨EISegä¸­ï¼Œç½‘ç»œåˆ†ä¸º`HRNet18s_OCR48`å’Œ`HRNet18_OCR64`ï¼Œå¹¶åˆ†åˆ«æä¾›äº†äººåƒå’Œé€šç”¨ä¸¤ç§æ¨¡å‹å‚æ•°ã€‚åœ¨æ­£ç¡®åŠ è½½æ¨¡å‹å‚æ•°åï¼Œå³ä¸‹è§’çŠ¶æ€æ ä¼šç»™äºˆè¯´æ˜ã€‚è‹¥ç½‘ç»œå‚æ•°ä¸æ¨¡å‹å‚æ•°ä¸ç¬¦ï¼Œå°†ä¼šå¼¹å‡ºè­¦å‘Šï¼Œæ­¤æ—¶åŠ è½½å¤±è´¥éœ€é‡æ–°åŠ è½½ã€‚æ­£ç¡®åŠ è½½çš„æ¨¡å‹å‚æ•°ä¼šè®°å½•åœ¨`è¿‘æœŸæ¨¡å‹å‚æ•°`ä¸­ï¼Œå¯ä»¥æ–¹ä¾¿åˆ‡æ¢ï¼Œå¹¶ä¸”ä¸‹æ¬¡æ‰“å¼€è½¯ä»¶æ—¶è‡ªåŠ¨åŠ è½½é€€å‡ºæ—¶çš„æ¨¡å‹å‚æ•°ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/20493e7446454ea6bc3f7648009ead3b700c8690aaee43cebedf4d97bec7125b)

2. **å›¾åƒåŠ è½½**

   æ–‡ä»¶$\to$æ‰“å¼€å›¾åƒ/å›¾åƒæ–‡ä»¶å¤¹ã€‚å½“çœ‹åˆ°ä¸»ç•Œé¢å›¾åƒæ­£ç¡®åŠ è½½ï¼Œ`æ•°æ®åˆ—è¡¨`æ­£ç¡®å‡ºç°å›¾åƒè·¯å¾„å³å¯ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/0475e4cbeb274e89a970b710f12dd2c84201903098ec40b3b6dcef4e02ba203a)

3. **æ ‡ç­¾æ·»åŠ /åŠ è½½**

   æ·»åŠ /åŠ è½½æ ‡ç­¾ã€‚å¯ä»¥é€šè¿‡`æ·»åŠ æ ‡ç­¾`æ–°å»ºæ ‡ç­¾ï¼Œæ ‡ç­¾åˆ†ä¸º4åˆ—ï¼Œåˆ†åˆ«å¯¹åº”åƒç´ å€¼ã€è¯´æ˜ã€é¢œè‰²å’Œåˆ é™¤ã€‚æ–°å»ºå¥½çš„æ ‡ç­¾å¯ä»¥é€šè¿‡`ä¿å­˜æ ‡ç­¾åˆ—è¡¨`ä¿å­˜ä¸ºtxtæ–‡ä»¶ï¼Œå…¶ä»–åˆä½œè€…å¯ä»¥é€šè¿‡`åŠ è½½æ ‡ç­¾åˆ—è¡¨`å°†æ ‡ç­¾å¯¼å…¥ã€‚é€šè¿‡åŠ è½½æ–¹å¼å¯¼å…¥çš„æ ‡ç­¾ï¼Œé‡å¯è½¯ä»¶åä¼šè‡ªåŠ¨åŠ è½½ã€‚  
![](https://ai-studio-static-online.cdn.bcebos.com/893d7ec1186a48678c3b18d21ef9dc7e07e0ce5381e94ce18e873530b630a04e)


4. **è‡ªåŠ¨ä¿å­˜è®¾ç½®**

   åœ¨ä½¿ç”¨ä¸­å¯ä»¥å°†`è‡ªåŠ¨ä¿å­˜`è®¾ç½®ä¸Šï¼Œè®¾å®šå¥½æ–‡ä»¶å¤¹å³å¯ï¼Œè¿™æ ·åœ¨ä½¿ç”¨æ—¶åˆ‡æ¢å›¾åƒä¼šè‡ªåŠ¨å°†å®Œæˆæ ‡æ³¨çš„å›¾åƒè¿›è¡Œä¿å­˜ã€‚

å½“è®¾ç½®å®Œæˆåå³å¯å¼€å§‹è¿›è¡Œæ ‡æ³¨ã€‚  

![](https://ai-studio-static-online.cdn.bcebos.com/4defd4610c914422b68dd78b42df807a08e54358ea4e41a3acfc8d3ff66e45f0)


#### **åŠ¨å›¾æ¼”ç¤º**
> å› ä¸ºè§†é¢‘æ¼”ç¤ºåœ¨è¿™é‡Œæ”¾ä¸ä¸Šå»ï¼Œæ‰€ä»¥ç›´æ¥å¼•ç”¨äº†å®˜æ–¹æ–‡æ¡£çš„åŠ¨å›¾ã€‚

![](https://user-images.githubusercontent.com/71769312/141130688-e1529c27-aba8-4bf7-aad8-dda49808c5c7.gif)

#### **æ ‡æ³¨æ•ˆæœ**
![](https://ai-studio-static-online.cdn.bcebos.com/ea4a91cedd94434d88496c57ca12477ac74e0e150e374d1491fb49115e397a44)
![](https://ai-studio-static-online.cdn.bcebos.com/e7db243366364fffa35fd5d84646f4f7c1053a6f2751466fb16cc0a263d929f3)


### 4. æ„é€ æ•°æ®é›†

#### **æ•°æ®å¢å¼º**
å¯¹æ•°æ®é›†ä¸­çš„æ•°æ®æé«˜å¯¹æ¯”åº¦ã€é¥±å’Œåº¦

#### **ä¿®æ”¹æ•°æ®é›†æ ‡ç­¾**
æ•°æ®é›†æä¾›çš„æ ‡æ³¨æ˜¯1-6ï¼Œè¿™é‡Œæ”¹ä¸º0-5


```python
import os
from PIL import Image
from tqdm import trange
import numpy as np

relab_path = "data/data55589/WHDLD/ImagesPNG_Relabel"
if not os.path.exists(relab_path):
    os.mkdir(relab_path)  # åˆ›å»ºæ–°æ ‡ç­¾çš„æ–‡ä»¶å¤¹

label_dir = 'data/data55589/WHDLD/ImagesPNG'
label_dir_list = os.listdir(label_dir)
for d in trange(len(label_dir_list)):
    im = Image.open(os.path.join(label_dir,label_dir_list[d]))  # æ‰“å¼€å›¾ç‰‡
    width = im.size[0]  # è·å–å®½åº¦
    height = im.size[1]  # è·å–é•¿åº¦
    im = np.array(im)
    for x in range(width):
        for y in range(height):
            label_origin = im[x, y]  # åŸåæ ‡å¯¹åº”çš„æ ‡ç­¾
            if (label_origin <= 6):
                im[x, y] -= 1  # 1-6å˜ä¸º0-5
            else:
                print(label_origin)
    new_im = Image.fromarray(im.astype(np.uint8), mode='P')
    new_im.save(os.path.join(relab_path, label_dir_list[d]))
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4940/4940 [22:43<00:00,  3.67it/s]


#### **å°†è®­ç»ƒé›†çš„å›¾åƒé›†å’Œæ ‡æ³¨è·¯å¾„å†™å…¥datasä¸­å¹¶æŠ½æ ·å¯è§†åŒ–**
- å·¦ï¼šåŸå›¾
- ä¸­ï¼šåŸæ ‡æ³¨
- å³ï¼šä¿®æ”¹åçš„æ ‡æ³¨


```python
import numpy as np
import os
import matplotlib.pyplot as plt
import cv2
import random
import time
import matplotlib.patches as mpatches

datas = []
image_base = 'data/data55589/WHDLD/Images'   # è®­ç»ƒé›†åŸå›¾è·¯å¾„
annos_base = 'data/data55589/WHDLD/ImagesPNG_Relabel'   # è®­ç»ƒé›†æ ‡ç­¾è·¯å¾„

# è¯»å–åŸå›¾æ–‡ä»¶å
ids_ = [v.split('.')[0] for v in os.listdir(image_base)]

# å°†è®­ç»ƒé›†çš„å›¾åƒé›†å’Œæ ‡ç­¾è·¯å¾„å†™å…¥datasä¸­
for id_ in ids_:
    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))
    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))
    datas.append((img_pt0.replace('/home/aistudio', ''), img_pt1.replace('/home/aistudio', '')))
    if os.path.exists(img_pt0) and os.path.exists(img_pt1):
        pass
    else:
        raise Exception("path invalid!")

# éšæœºæ‰“ä¹±datas
np.random.seed(int(time.time()))
np.random.shuffle(datas)

# æ‰“å°datasçš„é•¿åº¦
print('total:', len(datas))

# æŠ½æ ·å¯è§†åŒ–
def visualize(path, i, title):
    img = cv2.imread(path)[:, :, ::-1]
    plt.subplot(len(datas[15]), 3, i)
    plt.title(title)
    plt.imshow(img)

fig = plt.figure(figsize=(10, 7))
# å›¾ä¾‹
building = mpatches.Patch(color='red', label='Buildings')
road = mpatches.Patch(color='yellow', label='Road')
pavement = mpatches.Patch(color='darkkhaki', label='Pavement')
vegetation = mpatches.Patch(color='lime', label='Vegetation')
water = mpatches.Patch(color='mediumblue', label='Water')
soil = mpatches.Patch(color='grey', label='Bare Soil')
fig.legend(
    handles=[building, road, pavement, vegetation, water, soil],
    loc='upper center',
    ncol=6
)
# æ˜¾ç¤ºå›¾ç‰‡
visualize(datas[15][0], 1, datas[15][0][-10:])
visualize(os.path.join("data/data55589/WHDLD/ImagesPNG", datas[15][1][-10:]), 2, datas[15][1][-10:])
visualize(datas[15][1], 3, "relabeled " + datas[15][1][-10:])
```

    total: 4940


#### **å°†è®­ç»ƒé›†ã€æµ‹è¯•é›†å›¾ç‰‡è·¯å¾„å†™å…¥txtæ–‡ä»¶**


```python
# å››ç±»æ ‡ç­¾
labels = ['bare soil', 'building', 'pavement',  'road', 'vegetation', 'water']
num_classes = 6

# å°†labelså†™å…¥æ ‡ç­¾æ–‡ä»¶
with open('data/labels.txt', 'w') as f:
    for v in labels:
        f.write(v + '\n')

# éªŒè¯é›†ä¸è®­ç»ƒé›†çš„åˆ’åˆ†
split_num = int(0.1 * len(datas))  # 90%ä¸ºè®­ç»ƒé›†

# åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
train_data = datas[:-split_num]
val_data = datas[-split_num:-1]
test_data = datas[-1:]

# å†™å…¥è®­ç»ƒé›†list
with open('data/train_list.txt', 'w') as f:
    for img, lbl in train_data:
        f.write(img + ' ' + lbl + '\n')

# å†™å…¥éªŒè¯é›†list
with open('data/val_list.txt', 'w') as f:
    for img, lbl in val_data:
        f.write(img + ' ' + lbl + '\n')

# å†™å…¥æµ‹è¯•é›†list
with open('data/test_list.txt', 'w') as f:
    for img, lbl in test_data:
        f.write(img + ' ' + lbl + '\n')

# æ‰“å°è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†å¤§å°
print('train:', len(train_data))
print('val:', len(val_data))
print('test:', len(test_data))
```

    train: 4446
    val: 493
    test: 1


#### **æ„å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†**


```python
import paddleseg.transforms as T
from paddleseg.datasets import Dataset

dataset_root = './'  # æ•°æ®é›†æ ¹ç›®å½•
train_path = 'data/train_list.txt'  # è®­ç»ƒé›†txtæ–‡ä»¶
val_path = 'data/val_list.txt'  # éªŒè¯é›†txtæ–‡ä»¶

# å®šä¹‰è®­ç»ƒæ—¶çš„transforms
train_transforms = [
    T.RandomHorizontalFlip(0.5),  # éšæœºæ°´å¹³ç¿»è½¬
    T.RandomVerticalFlip(0.5),  # éšæœºå‚ç›´ç¿»è½¬
    # T.RandomDistort(
    #     brightness_range=0.2, brightness_prob=0.5,
    #     contrast_range=0.2, contrast_prob=0.5,
    #     saturation_range=0.2, saturation_prob=0.5,
    #     hue_range=15, hue_prob=0.5),
    T.Resize(target_size=(256, 256)),
    T.Normalize()
]
# å®šä¹‰éªŒè¯æ—¶çš„transforms
eval_transforms = [
    T.Resize((256, 256)),
    T.Normalize()
]

# æ„å»ºè®­ç»ƒé›†
train_dataset = Dataset(transforms = train_transforms,
                  dataset_root = dataset_root,
                  num_classes = num_classes,
                  train_path = train_path,
                  mode = 'train')
# æ„å»ºéªŒè¯é›†
eval_dataset = Dataset(transforms = eval_transforms,
                  dataset_root = dataset_root,
                  num_classes = num_classes,
                  val_path = val_path,
                  mode = 'val')
```

## äº”ã€æ¨¡å‹è®­ç»ƒ

### 1. æ¨¡å‹å‡†å¤‡

#### **æ„å»ºæ¨¡å‹**


```python
from paddleseg.models import HarDNet
from paddleseg.models import UNet

# è®¾ç½®è¿­ä»£æ¬¡æ•°
iters = 10000
# è®¾ç½®batch_size
batch_size = 128
# é€‰ç”¨HarDNetæ¨¡å‹
model = HarDNet(num_classes=num_classes, pretrained="model/model.pdparams")

# é€‰ç”¨UNetæ¨¡å‹
# model = UNet(num_classes=num_classes)
```

    2022-03-21 17:57:34 [INFO]	Loading pretrained model from model/model.pdparams
    2022-03-21 17:57:34 [INFO]	There are 347/347 variables loaded into HarDNet.


#### **æ„å»ºä¼˜åŒ–å™¨**


```python
import paddle
import paddleseg

# è®¾ç½®å­¦ä¹ ç‡
base_lr = 0.001
lr = paddle.optimizer.lr.PolynomialDecay(
    base_lr, 
    power=0.9, 
    decay_steps=iters, 
    end_lr=0
)
# è®¾ç½®ä¼˜åŒ–å™¨
optimizer = paddle.optimizer.Momentum(
    lr, 
    parameters=model.parameters(), 
    momentum=0.9, 
    weight_decay=4.0e-5
)
```

#### **æ„å»ºæŸå¤±å‡½æ•°**


```python
from paddleseg.models.losses import CrossEntropyLoss

# ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°
losses = {}
losses['types'] = [CrossEntropyLoss()]
losses['coef'] = [1]
```

### 2. æ¨¡å‹è®­ç»ƒ


```python
# æ¨¡å‹è®­ç»ƒ
from paddleseg.core import train
train(
    model=model,
    train_dataset=train_dataset,
    val_dataset=eval_dataset,
    optimizer=optimizer,
    save_dir='output',
    iters=iters,
    batch_size=batch_size,
    save_interval=200,
    log_iters=10,
    num_workers=0,
    losses=losses,
    use_vdl=True
)
```

## å…­ã€æ¨¡å‹è¯„ä¼°


```python
# æ¨¡å‹è¯„ä¼°
from paddleseg.core import evaluate
evaluate(
        model,
        eval_dataset
)
```

ç»è¿‡10000æ¬¡è®­ç»ƒï¼ŒmIOUå¯ä»¥è¾¾åˆ°0.69å·¦å³ï¼ŒAccå¯è¾¾0.87å·¦å³ã€‚
```
2022-03-17 15:19:50 [INFO]	[EVAL] #Images: 493 mIoU: 0.6923 Acc: 0.8736 Kappa: 0.8222 Dice: 0.8087
2022-03-17 15:19:50 [INFO]	[EVAL] Class IoU: 
[0.6245 0.6726 0.5249 0.8296 0.5456 0.9565]
2022-03-17 15:19:50 [INFO]	[EVAL] Class Acc: 
[0.7703 0.7968 0.68   0.9039 0.7765 0.9777]
```

### 3. æ•ˆæœå¯è§†åŒ–

#### **æ„å»ºæ¨¡å‹**


```python
from paddleseg.models import HarDNet
model = HarDNet(num_classes=num_classes)
```

#### **åˆ›å»ºtransform**


```python
import paddleseg.transforms as T
transforms = T.Compose([
    T.Resize(target_size=(256, 256)),
    T.Normalize()
])
```

#### **æ„å»ºå¾…é¢„æµ‹çš„å›¾åƒåˆ—è¡¨**


```python
import os
def get_image_list(image_path):
    '''
    è·å–å¾…é¢„æµ‹å›¾åƒ
    '''
    valid_suffix = [
        '.JPEG', '.jpeg', '.JPG', '.jpg', '.BMP', '.bmp', '.PNG', '.png'
    ]
    image_list = []
    image_dir = None
    if os.path.isfile(image_path):  # ä¼ å…¥å‚æ•°ä¸ºä¸€å¼ å›¾ç‰‡æ—¶
        if os.path.splitext(image_path)[-1] in valid_suffix:
            image_list.append(image_path)
    elif os.path.isdir(image_path):  # ä¼ å…¥å‚æ•°ä¸ºå«æœ‰å¤šå¼ å›¾ç‰‡çš„æ–‡ä»¶å¤¹æ—¶
        image_dir = image_path
        for root, dirs, files in os.walk(image_path):
            for f in files:
                if os.path.splitext(f)[-1] in valid_suffix:
                    image_list.append(os.path.join(root, f))
    else:
        raise FileNotFoundError(
            '`--image_path` is not found. it should be an image file or a directory including images'
        )

    if len(image_list) == 0:
        raise RuntimeError('There are not image file in `--image_path`')

    return image_list, image_dir

image_path = test_data[0][0]
image_list, image_dir = get_image_list(image_path)
```

#### **é¢„æµ‹**


```python
from paddleseg.core import predict

# è‡ªå®šä¹‰åˆ†å‰²é¢„æµ‹é¢œè‰²
custom_color = [
    255, 0, 0,  # building(red)
    255, 255, 0,  # road(yello)
    192, 192, 0,  # pavement(darkkhaki)
    0, 255, 0,  # vegetation(green)
    128, 128, 128,   # bare soil(gray)
    0, 0, 255  # water(blue)
]

predict(
    model,
    model_path='output/best_model/model.pdparams',
    # model_path="model/model.pdparams",  # æµ‹è¯•ç”¨
    transforms=transforms,
    image_list=image_list,
    image_dir=image_dir,
    save_dir='output/results',
    custom_color=custom_color
)
```

#### **é¢„æµ‹æ•ˆæœ**
- å·¦ï¼šåŸå›¾
- ä¸­ï¼šåŸæ ‡æ³¨å›¾åƒ
- å³ï¼šä¼ªå½©è‰²é¢„æµ‹æ•ˆæœ


```python
from matplotlib import pyplot as plt
import matplotlib.patches as mpatches

# å¾…å¯è§†åŒ–çš„å›¾åƒåˆ—è¡¨
img_list = [
    test_data[0][0],
    os.path.join("data/data55589/WHDLD/ImagesPNG", (test_data[0][0][-10:-3] + "png")),
    os.path.join("output/results/pseudo_color_prediction", (test_data[0][0][-10:-3] + "png")),
]

# å¯è§†åŒ–
fig = plt.figure(figsize=(10, 7))
# å›¾ä¾‹
building = mpatches.Patch(color='red', label='Buildings')
road = mpatches.Patch(color='yellow', label='Road')
pavement = mpatches.Patch(color='darkkhaki', label='Pavement')
vegetation = mpatches.Patch(color='lime', label='Vegetation')
water = mpatches.Patch(color='mediumblue', label='Water')
soil = mpatches.Patch(color='grey', label='Bare Soil')
fig.legend(
    handles=[building, road, pavement, vegetation, water, soil],
    loc='upper center',
    ncol=6
)
# æ‹¼æ¥å­å›¾ å·¦/ä¸­/å³: åŸå›¾/åŸæ ‡æ³¨/ä¼ªå½©è‰²é¢„æµ‹æ•ˆæœ
cnt = 0
for i in img_list:
    img = plt.imread(i)
    plt.subplot(231 + cnt)  # æ‹¼æ¥å­å›¾
    plt.title(i.split('/')[2] + "/" + i.split('/')[3])
    plt.imshow(img)
    cnt += 1
```

## ä¸ƒã€æ€»ç»“
æœ¬é¡¹ç›®ä»…ç”¨æ¥ç†Ÿæ‚‰PaddleSegä½¿ç”¨æµç¨‹ï¼Œæ—¥åæœ‰æœºä¼šä¼šå¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

- ä½œè€…ï¼šå‚¨æ°¢åˆé‡‘M.H.
- å±±è¥¿å†œä¸šå¤§å­¦æœ¬ç§‘ç”Ÿ
- å…´è¶£æ–¹å‘ï¼šè®¡ç®—æœºè§†è§‰ï¼Œå­¦ä¹ è§†è§‰SLAMä¸æ·±åº¦å­¦ä¹ ç»“åˆing
- ä¸ªäººä¸»é¡µï¼š
	- [GitHub](https://github.com/NEKOAKIKI)
   - [Gitee](https://gitee.com/nekoakiki)
	- [é£æ¡¨AI Studio](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/771061)
